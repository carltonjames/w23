{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"id":"1SPCENz_KDM-","nbgrader":{"grade":false,"grade_id":"cell-d1761bfdb43c7ec3","locked":true,"schema_version":3,"solution":false},"vscode":{"languageId":"r"}},"outputs":[],"source":["library(tidyverse)\n","library(stringr)\n","library(lubridate)\n","install.packages(\"nycflights13\")\n","library(nycflights13)\n","options(repr.plot.width=4, repr.plot.height=3)"]},{"cell_type":"markdown","source":["# Problem 1 - Factors with Flights\n","\n","## Part A (1 point)"],"metadata":{"id":"6RuyPfWaABA8"}},{"cell_type":"markdown","source":["We can use the function month in the lubridate package to add an additional column to `flights` with the name of each month (Jan, Feb, etc.). This is a factor column. (You will need to add this code to your answer for 1A)\n","\n"],"metadata":{"id":"IgVzG5SYD_mn"}},{"cell_type":"code","source":["flights %>%\n","  mutate(month_name = month(month, label = T)) %>%\n","  head() "],"metadata":{"id":"YjW2idCoJWG3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Part A \n","\n","**Using this factor column**, create an appropriate plot of the average departure delay for each season where season is defined based on the month of the flight. You should use functions from the `forcats` package where applicable (**do not use case_when**). Order your plot in decreasing order by the average departure delay. \n","\n","You should define each season as: \n","\n","Spring: March, April, May  \n","\n","Summer: June, July, August  \n","\n","Fall: September, October, November \n","\n","Winter: December, January, February \n","\n","Note: Answers that use case_when or do not use the month_name column will not recieve full credit. You must create the factor column and use forecats functions for this question. \n"],"metadata":{"id":"CS_msQBUGUpd"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"nPHwCBtsEJCB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Part B (1 point) \n","\n","Is there a relationship between departure delay and carrier? Convert the carrier column into a factor column with the top 3 most common carriers, with all other carriers represented as \"Other\". Use this column to create an appropriate plot that shows mean departure delay in each month for each of the 4 carrier levels. \n","\n","\n","**Note: You must use forecats functions to convert the carrier column. Answers that do not do this will not get full credit.**"],"metadata":{"id":"kiPsO6f1K0jl"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"DE1voopEO6aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Part C (1 point) \n","\n","What does the distribution of \"short\" delays (less than 60 minutes) look like for flights heading to one of 6 Midwest airports versus flights heading to any other airport? Create an appropriate visualization that shows the **distribution** of short delays for each one of the 6 airports in the `midwest_hubs` vector below, compared to the distribution for all other airports. (Your visualization should show the distribution of 7 different groups, one for each airport in the named vector, and one combining all airports not in the named vector). \n","\n","\n","\n","Hint 1: You should use a `forecats` function to collapse all destinations that are not in the midwest hubs vector to \"Other\". \n","\n","Hint 2: Remember that negative delays mean the flight was early. We are only interested in short delays, so make sure to remove flights that were early. "],"metadata":{"id":"EijfFLHJab4s"}},{"cell_type":"code","source":["midwest_hubs <- c(\"MSP\", \"DTW\", \"ORD\", \"MCI\", \"CLE\", \"STL\")"],"metadata":{"id":"oMWjrVInZiMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"avoHwNlNnqVS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Part D (1 point)\n","\n","Does manufacturer of the plane impact average departure delay? Group manufacturers into levels such that all of those whose planes were used in less than 10% of flights are combined together as one level and each other manufacturer used more or equal to 10% is their own category. Create a plot that displays the average depature delay for each of these manufacturers. **To make the manufacturers distinct, you should combine the AIRBUS and AIRBUS INDUSTRIE manufacturer levels together.** Order your plot in decreasing order by the average departure delay. \n","\n","Hint 1: The information about manufacturers is in the `planes` dataset. \n","\n","Hint 2: You should use the a `forecats` function to lump together all manufacturers whose planes are used in less than 10% of the dataset. Calculating out the proportion of flights in the dataset for each manufacturer is not necessary. \n","\n","Hint 3: Your plot should have an average departure delay for 4 groups. One of these should be AIRBUS, created by combining Airbus and Airbus Industrie together. Two of them should be other manufacturers with at least 10% of the planes in the dataset. The fourth should be \"Other\" which should group all of the other manufacturers together. "],"metadata":{"id":"qDSJ0vJZ2_dR"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"pJP8qMyaw2bS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 2\n","The file `tweets.txt.gz` contains tweets from June, 2009. The file is in a special format. The first few lines are:"],"metadata":{"id":"dJDYVm6qGBfc"}},{"cell_type":"code","source":["#download.file(\"https://github.com/stats306/w23/tree/main/homeworks/hw8/tweets.txt.gz\", \"tweets.txt.gz\")\n","readLines(\"tweets.txt.gz\", n = 11) %>% writeLines"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLMQlmrJGHEh","executionInfo":{"status":"ok","timestamp":1679115790111,"user_tz":240,"elapsed":9,"user":{"displayName":"Bach Viet Do","userId":"18232627323419064081"}},"outputId":"824fa5ac-4b9e-438d-9b59-1f9f0142dc76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["T\t2009-06-11 00:00:03\n","U\thttp://twitter.com/imdb\n","W\tNo Post Title\n","\n","T\t2009-06-11 16:37:14\n","U\thttp://twitter.com/ncruralhealth\n","W\tNo Post Title\n","\n","T\t2009-06-11 16:56:23\n","U\thttp://twitter.com/boydjones\n","W\tlistening to \"Big Lizard - The Dead Milkmen\" ♫ http://blip.fm/~81kwz\n"]}]},{"cell_type":"markdown","source":["Each datum consists of a triple of lines marked `T`, `U` and `W` containing the time of the tweet, the user, and the message itself, respectively. Each triple is separated by an empty line."],"metadata":{"id":"PB2CayssGf7u"}},{"cell_type":"markdown","source":["**2(a) (0.5 point)**\n","Read `tweets.txt.gz` in and store it as an R data frame/tibble called `tweets1`. It should have two character columns and 1.03m rows:\n","```{r}\n","# A tibble: 1,039,879 × 2\n","   X1    X2                                                                     \n","   <chr> <chr>                                                                  \n"," 1 T     \"2009-06-11 00:00:03\"                                                  \n"," 2 U     \"http://twitter.com/imdb\"                                              \n"," 3 W     \"No Post Title\"                                                        \n"," 4 T     \"2009-06-11 16:37:14\"                                                  \n"," 5 U     \"http://twitter.com/ncruralhealth\"                                     \n"," 6 W     \"No Post Title\"                                                        \n"," 7 T     \"2009-06-11 16:56:23\"                                                  \n"," 8 U     \"http://twitter.com/boydjones\"                                         \n"," 9 W     \"listening to \\\"Big Lizard - The Dead Milkmen\\\" ♫ http://blip.fm/~81kw…\n","10 T     \"2009-06-11 16:56:59\"                                                  \n","# … with 1,039,869 more rows\n","```\n","(**Hint**: The `.gz` file extension indicates that this file is compressed to save space. You can load the table using the **usual `tidyverse` table loading commands**, as if it were a regular text file."],"metadata":{"id":"fB7AeyDaGoU9"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"QJGlIS9cGe-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2(b) (0.5 point)**\n","Next, convert `tweets1` so that it has three columns reflecting the three variables present in this data set. Store the resulting table in a variable called `tweets2`. The first rows of `tweets2` will now look like:\n","```\n","# A tibble: 3 x 3\n","  T                   U                                W                       \n","  <chr>               <chr>                            <chr>                   \n","1 2009-06-11 00:00:03 http://twitter.com/imdb          No Post Title           \n","2 2009-06-11 16:37:14 http://twitter.com/ncruralhealth No Post Title           \n","3 2009-06-11 16:56:23 http://twitter.com/boydjones     \"listening to \\\"Big Liz…\n","```\n","(*Hint*: If you are having trouble getting this working on the full data set, try subsetting the table to a small number of rows in order to debug your code. Most likely you will use a function which requires each tripplet T, U, W to have the same row index.)"],"metadata":{"id":"WBpEubc3GuwA"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"gPUCzjPCG1L7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2(c) (0.5 point)**\n","Convert the `T` column to a properly formatted `datetime` object and give it (and the rest of the columns) an appropriate name. Also, strip off the leading `http://twitter.com/` from each user. Store the resulting table as `tweets3`. It will look like:\n","```\n","# A tibble: 346,627 × 3\n","   time                user          tweet                                      \n","   <dttm>              <chr>         <chr>                                      \n"," 1 2009-06-11 00:00:03 imdb          \"No Post Title\"                            \n"," 2 2009-06-11 16:37:14 ncruralhealth \"No Post Title\"                            \n"," 3 2009-06-11 16:56:23 boydjones     \"listening to \\\"Big Lizard - The Dead Milk…\n"," 4 2009-06-11 16:56:59 cameron987    \"@beatrizchavez A dork? NO way... you are.…\n"," 5 2009-06-11 16:57:03 selenato      \"@okaaaa 本当ね！2週間楽しみがありすぎわ、…\n"," 6 2009-06-11 16:57:30 nbeasley10    \"Just got a chance to buy All-Star tickets…\n"," 7 2009-06-11 16:57:31 littlewing333 \"@kidhum and if an act has pull and they d…\n"," 8 2009-06-11 16:57:33 lolcute       \"mebbe U fetch http://tinyurl.com/nz4fbr\"  \n"," 9 2009-06-11 16:57:36 fr0st22       \"I have broken 1,000 twitter updates. Paaa…\n","10 2009-06-11 16:57:59 mavellsyrup   \"Food timmeeee :'D\"                        \n","# … with 346,617 more rows\n","```"],"metadata":{"id":"Q3et2QFPG2vh"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"sNbaJNtpG_Q4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2(d) (1 point)**\n","Create a plot that shows the tweet volume for each day of June 2009. For what **day of the month** was there the largest volume of tweets? Can you give an explanation for what caused this spike?\n","\n","*Hint*: You can try to read tweets on the day of highest volume around or after 11.00PM and see what you find. Alternatively, you can Google the phrase \"events in June dd 2009\" where dd is the highest volume day."],"metadata":{"id":"ji7X4G-TG794"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"ASqLc1ziHBsG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2(e) (1 points)** One of the reason for the spike in 2(d) was related to a public figure in the music industry. On the day of highest volume in 2(d), what is the percentage of tweets that mentioned either **his first or last name** ? (No name abbreviation)"],"metadata":{"id":"ctqC29ScHDIh"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"ajo4NHNKLrz4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Challenge Problem: Writing a function\n","\n","(2 points) Black Friday occurs on the day after Thanksgiving and Thanksgiving falls on the fourth Thursday in November. Write a function `blackfriday_day(year)` which, given a year, returns the date of Black Friday for that year. Use your function to find the date of Black Friday for years 2010-2015. Here are some example years you can test your function on: \n","\n","    > blackfriday_day(2015)\n","    2015-11-27\n","    > blackfriday_day(2019)\n","    2019-11-29\n","    > blackfriday_day(2018)\n","    2018-11-23\n","    > blackfriday_day(3000)\n","    3000-11-28"],"metadata":{"id":"qUtlpiTQHG9j"}},{"cell_type":"code","source":["# YOUR SOLUTION HERE "],"metadata":{"id":"8sqaWZqHLn9P"},"execution_count":null,"outputs":[]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"provenance":[{"file_id":"1MqwLhhZ0da3C93R5K5SNDQVsVd4wr7B9","timestamp":1679093231173},{"file_id":"1C362dpDbnHsXnvJsj9MnyG6CdGfs_P1l","timestamp":1678744724075},{"file_id":"https://github.com/stats306/w23/blob/main/homeworks/hw7/hw7.ipynb","timestamp":1678730266611}]},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.2.1"}},"nbformat":4,"nbformat_minor":0}